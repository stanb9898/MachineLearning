fancyRpartPlot(m.rpart)
RpartPlot(m.rpart)
print(m.part)
m.rpart <- rpart(quality ~. , data = train)
m.rpart
print(m.part)
#for classification problem only
confusionMatrix(finalPredictions, y)
(348+153+433)/ nrow(test)
#Regresion trees
set.seed(7)
fit.nb <- train(taste~.-quality,data=train,method="rpart",metric=metric, trControl=control)
#Compare algorithms
transform_results <- resamples(list(GLMNET=fit.glmnet, SVM=fit.svm, KNN=fit.knn,NVM=fit.nb, RF =fit.rf, Rpart=fit.rpart))
fit.cart <- train(medv~., data=dataset, method="rpart", metric=metric,  trControl=control)
fit.cart <- train(taste~., data=data, method="rpart", metric=metric,  trControl=control)
#Compare algorithms
transform_results <- resamples(list(GLMNET=fit.glmnet, SVM=fit.svm, KNN=fit.knn,NVM=fit.nb, RF =fit.rf, CART=fit.rpart))
#Compare algorithms
transform_results <- resamples(list(GLMNET=fit.glmnet, SVM=fit.svm, KNN=fit.knn,NVM=fit.nb, RF =fit.rf, CART=fit.cart))
summary(transform_results)
dotplot(transform_results)
#CART
set.seed(7)
fit.cart <- train(taste~., data=data, method="rpart", metric=metric,  trControl=control)
#Compare algorithms
transform_results <- resamples(list(GLMNET=fit.glmnet, SVM=fit.svm, KNN=fit.knn,NVM=fit.nb, RF =fit.rf, CART=fit.cart))
summary(transform_results)
dotplot(transform_results)
#Compare algorithms
transform_results <- resamples(list(GLMNET=fit.glmnet, SVM=fit.svm, KNN=fit.knn,NVM=fit.nb,  CART=fit.cart))
summary(transform_results)
dotplot(transform_results)
#Compare algorithms
transform_results <- resamples(list(GLMNET=fit.glmnet, SVM=fit.svm, KNN=fit.knn,NVM=fit.nb, RF =fit.rf))
summary(transform_results)
dotplot(transform_results)
fit.rpart <- train(taste~.-quality,data=train,method="rpart",metric=metric, trControl=control)
#Compare algorithms
transform_results <- resamples(list(GLMNET=fit.glmnet, SVM=fit.svm, KNN=fit.knn,NVM=fit.nb, RF =fit.rf,rpart=fit.rpart))
summary(transform_results)
dotplot(transform_results)
#Compare algorithms
transform_results <- resamples(list(GLMNET=fit.glmnet, SVM=fit.svm, KNN=fit.knn,NVM=fit.nb, RF =fit.rf,rpart=fit.rpart))
summary(transform_results)
dotplot(transform_results)
#Compare algorithms
transform_results <- resamples(list(GLMNET=fit.glmnet, SVM=fit.svm, KNN=fit.knn,NVM=fit.nb, RF =fit.rf))
summary(transform_results)
dotplot(transform_results)
accuracy <- accuracy(finalPredictions,y)
(348+153+433)/ nrow(test)
# save the model to disk
saveRDS(fit.rf, "randomForest.rds")
#use the model for prediction
print("load the model")
model <- readRDS("randomForest.rds")
# make a predictions on "new data" using the final model
finalPredictions <- predict(model, x)
print(finalPredictions)
#for classification problem only
confusionMatrix(finalPredictions, y)
(349+153+434)/ nrow(test)
(348+153+433)/ nrow(test)
#calculate accuracy
table(predictions,test$taste)
(348+153+433)/ nrow(test)
model <- randomForest(taste ~ . - quality, data = train2)
model <- randomForest(taste ~ . - quality, data = train)
model
prediction <- predict(model, newdata = wine_test2)
prediction <- predict(model, newdata = test)
table(prediction, test$taste)
(353+152+433)/ nrow(test)
# make a predictions on "new data" using the final model
finalPredictions <- predict(model, x)
print(finalPredictions)
table(data$taste)
table(train$taste)
table(test$taste)
#calculate accuracy
table(predictions,test$taste)
table(prediction, test$taste)
model <- randomForest(taste ~ . - quality, data = train)
model
prediction <- predict(model, newdata = test)
table(prediction, test$taste)
(353+157+433)/ nrow(test)
model <- randomForest(taste ~ . - quality, data = train)
model
prediction <- predict(model, newdata = test)
table(prediction, test$taste)
#calculate accuracy
table(predictions,test$taste)
table(prediction, test$taste)
model <- randomForest(taste ~ . - quality, data = train)
model
prediction <- predict(model, newdata = test)
table(prediction, test$taste)
(345+150+437)/ nrow(test)
table(prediction, test$taste)
model <- randomForest(taste ~ . - quality, data = train)
model <- randomForest(taste ~ . - quality, data = test)
model
prediction <- predict(model, newdata = test)
table(prediction, test$taste)
(474+248+571)/ nrow(test)
model <- randomForest(taste ~ . - quality, data = train)
model
prediction <- predict(model, newdata = test)
table(prediction, test$taste)
(350+154+432)/ nrow(test)
prediction <- predict(model, newdata = test)
table(prediction, test$taste)
model <- randomForest(taste ~ . - quality, data = train)
model
prediction <- predict(model, newdata = test)
table(prediction, test$taste)
finalPredictions <- predict(model, x)
print(finalPredictions)
# make a predictions on "new data" using the final model
finalPredictions <- predict(model, x)
predictions <- predict(fit.rf, newdata=x)
print(predictions)
view(model)
data$taste <- ifelse(data$quality < 6, 'bad', 'good')
data$taste[data$quality == 6] <- 'normal'
data$taste <- as.factor(data$taste)
table(data$taste)
#1. Prepare problem
# a) Load libraries
library(ggplot2)
library(mlbench)
library(caret)
library(lattice)
library(e1071)
library(corrplot)
library(correlation)
library(randomForest)
library(rpart)
library(rpart.plot)
filename <- "wines.csv"
data <- read.csv(filename)
data1 <- data[, c("fixed.acidity", "volatile.acidity", "citric.acid", "residual.sugar", "chlorides","free.sulfur.dioxide","density","pH","sulphates","alcohol","quality") ]
# split into train
train_index <- sample(x=1:nrow(data), size=0.8*nrow(data))
train = data[train_index,]
test = data[-train_index,]
# 2. Summarize Data
# a) Descriptive statistics
# peek at data
head(data)
View(data)
sapply(data, class)
str(data)
summary(data)
anyNA(data)
data <- na.omit(data)
data1 <- na.omit(data1)
anyNA(data)
#point plot
ggplot(data , aes(x = fixed.acidity, y =quality)) +
geom_point()
#bar plot
ggplot(data, aes(fixed.acidity)) + geom_bar(fill="black")
ggplot(data, aes(type)) + geom_bar(fill="black")
ggplot(data = data) + geom_bar(mapping = aes(x = quality), fill="gray")
ggplot(data = data) + geom_bar(mapping = aes(x = quality), fill="gray")
data$taste <- ifelse(data$quality < 6, 'bad', 'good')
data$taste[data$quality == 6] <- 'normal'
data$taste <- as.factor(data$taste)
table(data$taste)
ggplot(data, aes(density)) + geom_bar(fill="black")
ggplot(data, aes(pH)) + geom_bar(fill="black")
importance(fit.rf)
importance(model)
importance(model)
model <- randomForest(taste ~ . - quality, data = train)
model
data$taste <- ifelse(data$quality < 6, 'bad', 'good')
data$taste[data$quality == 6] <- 'normal'
data$taste <- as.factor(data$taste)
table(data$taste)
model <- randomForest(taste ~ . - quality, data = train)
model
prediction <- predict(model, newdata = test)
table(prediction, test$taste)
# split into train
train_index <- sample(x=1:nrow(data), size=0.8*nrow(data))
train = data[train_index,]
test = data[-train_index,]
#Run algorithms using 10-fold cross validation
control <- trainControl(method="repeatedcv", number=10)
metric <- "Accuracy"
#GLMNET
set.seed(7)
fit.glmnet <- train(taste~.-quality, data=train, method="glmnet", metric=metric, trControl=control)
# SVM
set.seed(7)
fit.svm <- train(taste~.-quality, data=train, method="svmRadial", metric=metric, trControl=control)
# b) nonlinear algorithms
#knn
set.seed(7)
fit.knn <- train(taste~.-quality, data=train, method="knn", metric=metric, trControl=control)
#randomForest
set.seed(7)
fit.rf <- train(taste~.-quality, data=train, method="rf", metric=metric, trControl=control)
#Naive Bayes
set.seed(7)
fit.nb <- train(taste~.-quality,data=train,method="nb",metric=metric, trControl=control)
#calculate accuracy
table(predictions,test$taste)
data$taste <- ifelse(data$quality < 6, 'bad', 'good')
data$taste[data$quality == 6] <- 'normal'
data$taste <- as.factor(data$taste)
table(data$taste)
# look at parameters used for Random forest--best model
print(fit.rf)
library(ggplot2)
library(mlbench)
library(caret)
library(lattice)
library(e1071)
library(corrplot)
library(correlation)
library(randomForest)
library(rpart)
library(rpart.plot)
library(ggplot2)
library(mlbench)
library(caret)
library(lattice)
library(e1071)
library(corrplot)
library(correlation)
library(randomForest)
library(rpart)
library(rpart.plot)
filename <- "wines.csv"
data <- read.csv(filename)
data1 <- data[, c("fixed.acidity", "volatile.acidity", "citric.acid", "residual.sugar", "chlorides","free.sulfur.dioxide","density","pH","sulphates","alcohol","quality") ]
train_index <- sample(x=1:nrow(data), size=0.8*nrow(data))
train = data[train_index,]
test = data[-train_index,]
train_index <- sample(x=1:nrow(data), size=0.8*nrow(data))
train = data[train_index,]
test = data[-train_index,]
head(data)
View(data)
tail(data)
summary(data)
str(data)
sapply(data, class)
anyNA(data)
data <- na.omit(data)
data1 <- na.omit(data1)
anyNA(data)
# data dimension
dim(data)
#point plot
ggplot(data , aes(x = fixed.acidity, y =quality)) +
geom_point()
#bar plot
ggplot(data, aes(fixed.acidity)) + geom_bar(fill="black")
ggplot(data, aes(type)) + geom_bar(fill="black")
ggplot(data = data) + geom_bar(mapping = aes(x = quality), fill="gray")
ggplot(data, aes(pH)) + geom_bar(fill="black")
data$taste <- ifelse(data$quality < 6, 'bad', 'good')
data$taste[data$quality == 6] <- 'normal'
data$taste <- as.factor(data$taste)
table(data$taste)
# split into train
train_index <- sample(x=1:nrow(data), size=0.8*nrow(data))
train = data[train_index,]
test = data[-train_index,]
#Run algorithms using 10-fold cross validation
control <- trainControl(method="repeatedcv", number=10)
metric <- "Accuracy"
set.seed(7)
fit.glmnet <- train(taste~.-quality, data=train, method="glmnet", metric=metric, trControl=control)
# SVM
set.seed(7)
fit.svm <- train(taste~.-quality, data=train, method="svmRadial", metric=metric, trControl=control)
# b) nonlinear algorithms
#knn
set.seed(7)
fit.knn <- train(taste~.-quality, data=train, method="knn", metric=metric, trControl=control)
#randomForest
set.seed(7)
fit.rf <- train(taste~.-quality, data=train, method="rf", metric=metric, trControl=control)
#Naive Bayes
set.seed(7)
fit.nb <- train(taste~.-quality,data=train,method="nb",metric=metric, trControl=control)
transform_results <- resamples(list(GLMNET=fit.glmnet, SVM=fit.svm, KNN=fit.knn,NVM=fit.nb, RF =fit.rf))
summary(transform_results)
dotplot(transform_results)
data$taste <- ifelse(data$quality < 6, 'bad')
data$taste <- ifelse(data$quality < 6, 'bad', 'good')
data$taste[data$quality == 6] <- 'normal'
data$taste <- as.factor(data$taste)
table(data$taste)
#Compare algorithms
transform_results <- resamples(list(GLMNET=fit.glmnet, SVM=fit.svm, KNN=fit.knn,NVM=fit.nb, RF =fit.rf))
summary(transform_results)
dotplot(transform_results)
# look at parameters used for Random forest--best model
print(fit.rf)
confusionMatrix(predictions$class, dataTest$quality)
#for classification problem only
confusionMatrix(finalPredictions, y)
#Run algorithms using 10-fold cross validation
control <- trainControl(method="cv", number=10)
metric <- "Accuracy"
# a) linear algorithms
#GLMNET
set.seed(7)
fit.glmnet <- train(taste~.-quality, data=train, method="glmnet", metric=metric, trControl=control)
# SVM
set.seed(7)
fit.svm <- train(taste~.-quality, data=train, method="svmRadial", metric=metric, trControl=control)
# b) nonlinear algorithms
#knn
set.seed(7)
fit.knn <- train(taste~.-quality, data=train, method="knn", metric=metric, trControl=control)
#randomForest
set.seed(7)
fit.rf <- train(taste~.-quality, data=train, method="rf", metric=metric, trControl=control)
#Naive Bayes
set.seed(7)
fit.nb <- train(taste~.-quality,data=train,method="nb",metric=metric, trControl=control)
#Compare algorithms
transform_results <- resamples(list(GLMNET=fit.glmnet, SVM=fit.svm, KNN=fit.knn,NVM=fit.nb, RF =fit.rf))
summary(transform_results)
dotplot(transform_results)
fit.glmnet <- train(taste~.-quality, data=train, method="cv", metric=metric, trControl=control)
fit.svm <- train(taste~.-quality, data=train, method="cv", metric=metric, trControl=control)
trainControl <- trainControl(method="cv", number=10, repeats=3)
trainControl <- trainControl(method="cv", number=10)
# evaluate the model
fit <- train(taste~.-quality, data=train, trControl=trainControl, method="rf")
# display the results
print(fit)
fit.lm <- train(taste~.-quality, data=train, method="lm", metric=metric, preProc=c("center", "scale"), trControl=control)
# look at parameters used for Random forest--best model
print(fit.rf)
summary(transform_results)
bwplot(results)
bwplot(transform_results)
# look at parameters used for Random forest--best model
print(fit.rf)
# look at parameters used for Random forest--best model
print(fit.rf)
x <- test[,1:13]
y <- test[,14]
predictions <- predict(fit.rf, newdata=x)
print(predictions)
#calculate accuracy
table(predictions,test$taste)
(348+153+433)/ nrow(test)
#calculate accuracy
table(predictions,test$taste)
(348+153+433)/ nrow(test)
#for classification problem only
confusionMatrix(finalPredictions, y)
predictions <- predict(fit.rf, newdata=x)
print(predictions)
#calculate accuracy
table(predictions,test$taste)
(348+153+433)/ nrow(test)
# save the model to disk
saveRDS(fit.rf, "randomForest.rds")
#use the model for prediction
print("load the model")
model <- readRDS("randomForest.rds")
# make a predictions on "new data" using the final model
finalPredictions <- predict(model, x)
print(finalPredictions)
model <- randomForest(taste ~ . - quality, data = train)
model
prediction <- predict(model, newdata = test)
table(prediction, test$taste)
(350+154+432)/ nrow(test)
#for classification problem only
confusionMatrix(finalPredictions, y)
(347+159+412)/ nrow(test)
# look at parameters used for Random forest--best model
print(fit.rf)
#1. Prepare problem
# a) Load libraries
library(ggplot2)
library(mlbench)
library(caret)
library(lattice)
library(e1071)
library(corrplot)
library(correlation)
library(randomForest)
library(rpart)
library(ggplot2)
library(mlbench)
library(caret)
library(lattice)
library(e1071)
library(corrplot)
library(correlation)
library(randomForest)
library(rpart)
library(rpart.plot)
# 2. Summarize Data
# a) Descriptive statistics
# peek at data
head(data)
data <- na.omit(data)
data1 <- na.omit(data1)
anyNA(data)
#point plot
ggplot(data , aes(x = fixed.acidity, y =quality)) +
geom_point()
summary(transform_results)
summary(transform_results)
dotplot(transform_results)
print(predictions)
#calculate accuracy
table(predictions,test$taste)
# look at parameters used for Random forest--best model
print(fit.rf)
View(control)
View(transform_results)
#Compare algorithms
transform_results <- resamples(list(GLMNET=fit.glmnet, SVM=fit.svm, KNN=fit.knn,NVM=fit.nb, RF =fit.rf))
summary(transform_results)
View(transform_results)
ggplot(data, aes(type)) + geom_bar(fill="black")
#bar plot
ggplot(data, aes(fixed.acidity)) + geom_bar(fill="black")
ggplot(data = data) + geom_bar(mapping = aes(x = quality), fill="gray")
ggplot(data, aes(pH)) + geom_bar(fill="black")
ggplot(data = data) + geom_bar(mapping = aes(x = quality), fill="gray")
table(data$taste)
fit.svm <- train(taste~.-quality, data=train, method="scv", metric=metric, trControl=control)
fit.svm <- train(taste~.-quality, data=train, method="svm", metric=metric, trControl=control)
library(caret)
fit.nb <- train(taste~.-quality,data=train,method="nb",metric=metric, trControl=control)
View(fit.nb)
View(fit.nb)
#calculate accuracy
table(predictions,test$taste)
(348+153+433)/ nrow(test)
# look at parameters used for Random forest--best model
print(fit.rf)
model
# look at parameters used for Random forest--best model
print(fit.rf)
#Run algorithms using 10-fold cross validation
control <- trainControl(method="cv", number=10)
metric <- "RMSE"
#GLMNET
set.seed(7)
fit.glmnet <- train(taste~.-quality, data=train, method="glmnet", metric=metric, trControl=control)
#randomForest
set.seed(7)
fit.rf <- train(taste~.-quality, data=train, method="rf", metric=metric, trControl=control)
#GLMNET
set.seed(7)
fit.glmnet <- train(taste~.-quality, data=train, method="glmnet", metric=metric, trControl=control)
#knn
set.seed(7)
metric <- "Accuracy"
#GLMNET
set.seed(7)
fit.glmnet <- train(taste~.-quality, data=train, method="glmnet", metric=metric, trControl=control)
#knn
set.seed(7)
fit.knn <- train(taste~.-quality, data=train, method="knn", metric=metric, trControl=control)
#Naive Bayes
set.seed(7)
fit.nb <- train(taste~.-quality,data=train,method="nb",metric=metric, trControl=control)
#randomForest
set.seed(7)
fit.rf <- train(taste~.-quality, data=train, method="rf", metric=metric, trControl=control)
# split into train
train_index <- sample(x=1:nrow(data), size=0.8*nrow(data))
fit.lm <- train(taste~.-quality, data=dataset_features, method="lm", metric=metric, preProc=c("center", "scale"), trControl=control)
#randomForest
set.seed(7)
fit.rf <- train(taste~.-quality, data=train, method="rf", metric=metric, trControl=control)
#calculate accuracy
table(predictions,test$taste)
model <- randomForest(taste ~ . - quality, data = train)
model
prediction <- predict(model, newdata = test)
table(prediction, test$taste)
#for classification problem - view accuracy
confusionMatrix(finalPredictions, y)
#Compare algorithms
transform_results <- resamples(list(GLMNET=fit.glmnet, KNN=fit.knn,NVM=fit.nb, RF =fit.rf))
summary(transform_results)
dotplot(transform_results)
#bar plot
ggplot(data, aes(fixed.acidity)) + geom_bar(fill="black")
ggplot(data, aes(type)) + geom_bar(fill="black")
ggplot(data = data) + geom_bar(mapping = aes(x = quality), fill="gray")
ggplot(data, aes(pH)) + geom_bar(fill="black")
anyNA(data)
#bar plot
ggplot(data, aes(fixed.acidity)) + geom_bar(fill="black")
ggplot(data, aes(type)) + geom_bar(fill="black")
ggplot(data = data) + geom_bar(mapping = aes(x = quality), fill="gray")
ggplot(data, aes(pH)) + geom_bar(fill="black")
dotplot(transform_results)
#for classification problem - view accuracy
confusionMatrix(finalPredictions, y)
